# Robots.txt for Saymon's Portfolio Website
# Allow crawling everything by default
User-agent: *
Allow: /

# Sitemap location
Sitemap: https://saymon.ca/sitemap.xml

# Crawl delay (be respectful to servers)
Crawl-delay: 1

# Specific rules for different bots
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Slurp
Allow: /

# Block access to admin or private areas (if any)
Disallow: /admin/
Disallow: /private/
Disallow: /api/

# Allow access to important files
Allow: /favicon.ico
Allow: /sitemap.xml
Allow: /robots.txt

# Resume handling - allow both paths but prefer the HTML page
Allow: /resume
Allow: /resume.pdf
